# XpertEval: All-in-One Evaluation Framework for Multimodal Large Models

XpertEval is a comprehensive evaluation system specifically designed for multimodal large language models (MLLMs), with a unique focus on both general capabilities and professional expertise in Traditional Chinese Medicine (TCM).

## Key Features

- **Comprehensive Multimodal Evaluation**: Assesses text understanding, visual recognition, audio processing, and cross-modal fusion capabilities
- **TCM Domain Expertise Assessment**: Evaluates specialized capabilities in visual diagnosis (face and tongue inspection), auditory diagnosis (sound analysis), inquiry diagnosis (text Q&A), and pulse-taking diagnosis
- **OpenAI-Compatible API Testing**: Supports evaluation via API for various models without local deployment
- **Standardized Metrics Suite**: Implements extensive metrics for quantitative performance measurement
- **Modular and Extensible Design**: Easy to customize and extend for different models and domains
- **Visualization Tools**: Provides intuitive visualizations of evaluation results for model comparison

## Use Cases

- Benchmark multiple MLLMs on general capabilities
- Evaluate specialized medical diagnostic abilities in TCM
- Track model improvement across iterations
- Conduct focused assessments on specific modalities
- Generate standardized reports for model capabilities

XpertEval bridges the gap between general-purpose evaluation and domain-specific assessment, making it an essential tool for researchers and practitioners working with multimodal AI in specialized fields.

[Documentation](https://rookie-littleblack.github.io/XpertEval/) | [API Guide](README_API.md) | [Quickstart](docs/quickstart.md) 